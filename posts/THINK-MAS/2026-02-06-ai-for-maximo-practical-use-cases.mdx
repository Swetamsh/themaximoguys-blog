---
title: "AI for Maximo: Practical Intelligence Beyond the Hype"
description: "Five proven AI use cases for Maximo with ROI frameworks: work order intelligence, predictive maintenance, visual inspection, conversational AI, and data quality improvement."
date: "2026-02-06"
slug: "ai-for-maximo-practical-use-cases"
tags: ["MAS 9", "AI", "watsonx", "Predictive Maintenance", "Visual Inspection", "RAG", "Machine Learning", "IoT"]
draft: false
tier: "developer"
author: "The Maximo Guys"
authorAvatar: "https://images.unsplash.com/photo-1472099645785-5658abf4ff4e?w=150&h=150&fit=crop"
coverImage: "https://raw.githubusercontent.com/Swetamsh/themaximoguys-blog/main/posts/THINK-MAS/images/think-mas-part-10.png"

authorTitle: "Maximo Technical Team"
authorBio: "Technical practitioners with decades of combined experience implementing IBM Maximo across industries."
authorCredentials: ["IBM Certified Maximo Consultants", "Cloud-Native Architecture Specialists"]

faqs:
  - question: "What are the most practical AI use cases for Maximo?"
    answer: "Five proven use cases deliver immediate ROI: work order intelligence (75% time savings), predictive maintenance (60% cost reduction), visual inspection automation (81% time savings), conversational AI assistant (40 min/WO saved), and AI-powered data quality improvement (97% accuracy)."
  - question: "How long does it take to implement AI for Maximo?"
    answer: "The five-phase implementation model takes 12-18 months: business case (1 month), data foundation (3 months), model development (3 months), pilot (3 months), and enterprise rollout (6 months). Rushing the pilot phase causes 70% of production failures."
  - question: "Why do most enterprise AI projects fail?"
    answer: "87% of AI projects never reach production. The primary reasons are starting with a technology mandate instead of a business problem, underestimating data quality requirements (85% of failures stem from poor data), and lack of explainability that kills user trust and adoption."

keyTakeaways:
  - "Five proven AI use cases deliver measurable ROI in production today"
  - "Data quality determines AI quality -- invest 50% of project time on data foundation"
  - "Human-in-the-loop is mandatory: AI suggests, humans decide for high-risk actions"
  - "watsonx integration provides purpose-built asset management AI, not general-purpose AGI"
  - "Implementation follows five phases over 12-18 months; rushing pilots causes 70% of failures"

series:
  name: "THINK MAS"
  part: 10
  total: 12
---

# AI for Maximo: Practical Intelligence Beyond the Hype

> **Who this is for:** Maximo administrators, reliability engineers, data scientists, and IT leaders evaluating practical AI use cases for asset management -- especially those who want proven ROI frameworks instead of AI hype.

**Read Time:** 20-22 minutes

---

## Introduction: The $850K AI Investment That Actually Delivered

A global manufacturing company's 18-month AI journey:

**Phase 1 - Work Order Intelligence:** watsonx.ai transformed "Pump broke. Fixed it." into comprehensive technical documentation capturing failure modes, root causes, and preventive recommendations. **Result:** 75% time reduction (47 min to 12 min), work order quality 32% to 89%.

**Phase 2 - Predictive Maintenance:** Maximo Predict with sensor data reduced PM work orders 55% (847 to 380/month) while improving prediction accuracy from 38% to 91%. **Result:** Unplanned downtime 73% reduction (127 to 34 hours/month).

**Phase 3 - Visual Inspection:** Maximo Visual Inspection automated defect detection via drone imagery. **Result:** 81% inspection time savings (450 to 85 hours/month), detection accuracy 73% to 96%.

**Total Impact:** $1.31M annual savings, 154% first-year ROI, 7.8-month payback.

This blog explores five practical AI use cases with implementation frameworks proven in production.

---

## Part 1: The Reality Check

### Why Most Enterprise AI Fails

**87% of AI projects never reach production.** Common failures:

**Failure 1: Solution Seeking Problem**

- Executive mandate: "We need AI!"
- $2M platform investment
- No business problem defined
- Zero production deployments
- Quietly canceled after 18 months

**Failure 2: Data Quality Underestimated**

- Planned: 6 months implementation
- Reality: 12 months data cleaning + 6 months implementation
- Cost: 4x budget

**Failure 3: Black Box Problem**

- AI: "Asset will fail in 7 days (87% confidence)"
- Manager: "Why?"
- Data Scientist: "Neural network patterns..."
- Manager: "So why?"
- Result: No trust, no adoption

### Maximo AI: Purpose-Built Intelligence

MAS integrates with IBM watsonx:

```
watsonx.ai → Foundation models, RAG, fine-tuning
watsonx.data → Data lake, governance, catalog
watsonx.governance → Model monitoring, compliance
     ↓
MAS Applications (Manage, Health, Predict, Visual Inspection, Assist, Monitor)
```

NOT general-purpose AGI. IS purpose-built for asset management.

> **Key insight:** 87% of enterprise AI projects never reach production. The difference between the failed 87% and the successful 13% is starting with a quantified business problem -- not a technology mandate. "Pump documentation takes 47 minutes" beats "We need AI" every time.

---

## Part 2: Five Practical Use Cases

### Use Case 1: Work Order Intelligence

**Problem:** "Pump broke. Fixed it." loses 95% of tribal knowledge.

**AI Solution:** Generative AI enhancement

**Architecture:**

```
Inputs → watsonx.ai (Granite LLM + RAG) → Enhanced Output

- Work notes
- Parts used
- Labor hours
- Attachments
- Historical similar WOs
```

**Transformation Example:**

*Before:* "Pump #4 making noise. Replaced bearing. Works now."

*After (AI-Enhanced):*

```
EQUIPMENT: Centrifugal pump P-104 (Cooling water)

SYMPTOM: Abnormal vibration 12.4 mm/s (normal: <3.5)
Temperature 85 C (normal: 60-65 C)

ROOT CAUSE: Bearing failure - inadequate lubrication
- Bearing race pitting and spalling
- Insufficient grease
- Last lubrication: 8 months ago (spec: 3 months)

CORRECTIVE ACTION:
1. Drained system
2. Disconnected motor
3. Removed damaged bearing (SKF 6310)
4. Cleaned housing
5. Installed new bearing with proper clearance
6. Applied grease (Mobilux EP2, 40g)
7. Reassembled
8. Aligned coupling (0.05mm tolerance)
9. Pressure tested
10. Verified vibration: 2.1 mm/s (acceptable)

PREVENTIVE RECOMMENDATIONS:
- Lubrication PM every 3 months
- Install vibration sensor
- Train operators on warning signs

PARTS: SKF 6310 bearing, Mobilux EP2 grease, coupling gasket
DOWNTIME: 4.5 hours
FOLLOW-UP: Monitor vibration 7 days
REFERENCE: WO-11782, WO-10934
```

**ROI:**

- Time: 47 min to 12 min (-75%)
- Annual savings: $6.28M (conservative)
- Implementation: $180K/year licensing + $160K one-time

### Use Case 2: Predictive Maintenance (Maximo Predict)

**Problem:** Preventive maintenance = expensive guesswork

- $1.2M/year unnecessary PM
- $2.1M/year unplanned downtime

**AI Solution:** Condition-based predictions

**Data Flow:**

```
Maximo Monitor (IoT/Sensors) →
Maximo Manage (Failure History) →
watsonx.data (Data Lake) →
Watson Studio (Model Training) →
Watson Machine Learning (Scoring) →
Maximo Predict (Predictions) →
Maximo Manage (Auto Work Orders)
```

**Three Model Types:**

*1. Failure Probability*

- Input: Vibration, temperature, operating hours, failure history
- Model: Random Forest
- Output: Probability 0-100%
- Trigger: >70% = create WO, 40-70% = inspect, &lt;40% = monitor

*2. Remaining Useful Life (RUL)*

- Input: Current condition, degradation rate, usage, maintenance history
- Model: LSTM Neural Network
- Output: Days until failure
- Trigger: &lt;7 days = emergency, &lt;30 days = schedule, &lt;90 days = order parts

*3. Anomaly Detection*

- Input: Real-time sensor stream, baseline, thresholds
- Model: Isolation Forest/Autoencoder
- Output: Anomaly score 0-100
- Trigger: >90 = immediate alert, >70 = investigate

**Implementation:** 12-month phased approach

1. Data Foundation (Months 1-3): Install Monitor, connect sensors, validate data
2. Model Development (Months 4-6): Train in Watson Studio, deploy to ML
3. Pilot (Months 7-9): Shadow mode validation
4. Production (Months 10-12): Full rollout

**ROI:**

- Baseline: $3.75M/year (PM + downtime + inventory)
- With Predict: $1.51M/year (-60%)
- Annual savings: $2.24M
- First year net: $1.57M (463% ROI)

### Use Case 3: Visual Inspection Automation

**Problem:** Manual inspections slow, expensive, inconsistent

- 3-5 hours per inspection
- $225-375 cost
- 4,000 inspections/year = $1.2M

**AI Solution:** Maximo Visual Inspection

**Architecture:**

```
Image Capture (drones/cameras/mobile/robots) →
Edge Processing (MVI Edge - optional) →
Maximo Visual Inspection (Computer Vision) →
  - Object detection
  - Classification
  - Segmentation
Maximo Manage (auto-create inspection records + work orders)
```

**Defect Types:**

- Utility: Cracks, corrosion, vegetation, insulator damage, oil leaks
- Manufacturing: Wear patterns, alignment, fluid leaks, surface defects
- Solar/Wind: Panel cracks, hot spots, debris, blade damage

**Solar Farm Example:**

*Before MVI:*

- 50,000 panels
- 2 technicians x 30 days = 3.3 months
- Cost: $96K per cycle
- Frequency: 2x/year
- Defects found: 120/cycle
- Miss rate: 25%

*After MVI:*

- 1 drone operator x 5 days
- Flight: 12.5 hours, AI processing: 2 hours, Human review: 8 hours
- Cost: $12K per cycle
- Frequency: 6x/year
- Defects found: 145/cycle
- Miss rate: 3%
- **Annual savings: $120K + earlier detection value**

**Training Process:**

1. Collect 100-1000+ images per defect type
2. Annotate with bounding boxes and classifications
3. Train with transfer learning (ResNet/EfficientNet)
4. Validate: 80% train, 10% validate, 10% test
5. Deploy: Cloud or edge inference
6. Target accuracy: >95% for critical defects

### Use Case 4: Conversational AI Assistant

**Problem:** Technicians waste 30-40 minutes searching for information

**AI Solution:** watsonx Assistant with RAG

**Architecture:**

```
User Query: "How do I replace bearing on pump P-104?"
     ↓
watsonx Assistant (NLP, intent classification)
     ↓
Vector Database Search:
- Work order history
- Maintenance manuals
- Safety procedures
- Parts catalogs
- Training materials
     ↓
Retrieve Top 5 Relevant Documents
     ↓
watsonx.ai LLM (prompt engineering)
     ↓
Response: Step-by-step instructions with:
- Safety precautions
- Tools needed
- Parts required
- Detailed steps
- Related work orders
- Expert contact info
```

**Five Key Capabilities:**

1. **Asset Lookup:** Details, status, location, recent work orders, meter readings
2. **Work Order Creation:** Guided questions, auto-populate fields, suggest similar WOs
3. **Troubleshooting:** Diagnostic decision tree, likely causes, relevant procedures
4. **Parts/Inventory:** Stock levels, location, reorder points, alternates
5. **Remote Expert:** Video-based support with real-time annotations

**Implementation:**

- Phase 1 (3 months): Knowledge base preparation
- Phase 2 (2 months): Assistant configuration
- Phase 3 (3 months): Pilot with 20-30 users
- Phase 4 (6 months): Enterprise rollout

### Use Case 5: Data Quality Improvement

**Problem:** Poor data undermines everything

- Duplicate assets: "PUMP-104", "Pump 104", "P-104" (same asset)
- Inconsistent domains: Priority "1", "High", "URGENT", "Critical"
- Missing data: 37% assets without location, 62% WOs without failure codes
- Invalid data: Future install dates, negative hours

**AI Solutions:**

*1. Intelligent Deduplication*

```
Problem: 50,000 assets, ~5,000 duplicates

Traditional: 3 analysts x 6 months = $180K

AI Approach:
- String similarity (Levenshtein, Jaro-Winkler, Soundex)
- ML model trained on labeled examples
- Features: text similarity, location proximity, manufacturer, model, install date
- Output: Probability 0-100%

Workflow:
- High confidence (>90%): Auto-merge
- Medium (70-90%): Human review
- Low (<70%): Keep separate

Result: 2 days processing + 1 week review = $25K, 97% accuracy
Savings: $155K
```

*2. Data Enrichment*

```
Problem: 62% work orders missing failure codes

AI Solution: NLP extraction from work order text

Example:
"Pump bearing failed due to lack of lubrication.
Replaced bearing SKF 6310. Added lubrication PM."

NLP Extraction:
- Component: Bearing
- Failure mode: Lack of lubrication
- Action: Replaced
- Part: SKF 6310

Suggested Codes:
- Problem: BEARLUB (Bearing Lubrication)
- Failure Class: MAINT (Maintenance Related)
- Cause: INADLUB (Inadequate Lubrication)

Result: Failure code completion 62% → 94%
```

*3. Real-Time Validation*

```
Problem: Invalid data being entered

Example: User enters install date "2030-05-15"

AI Validation:
1. Detect impossible value (future date)
2. Check historical patterns
3. Suggest: "Did you mean 2020-05-15?"
4. Explain: "Install dates cannot be future. Similar assets: 2018-2020."
5. Require confirmation if override

Result: 89% reduction in invalid data
```

> **Key insight:** Work order intelligence, predictive maintenance, visual inspection, conversational AI, and data quality improvement are all running in production today with measurable ROI. The question is not "Can AI help Maximo?" but "Which business problem should you solve first?"

---

## Part 3: Implementation Framework

### Five-Phase Model

**Phase 1: Business Case (Month 1)**

- Identify pain point with quantified metrics
- Assess data availability and quality
- Define success metrics (primary/secondary/tertiary)
- Secure executive sponsorship and budget
- **Deliverable:** Business case, ROI, project charter

**Phase 2: Data Foundation (Months 2-4)**

- Data discovery and quality assessment
- Cleansing: Remove duplicates, standardize, fill gaps
- Integration: Connect sources, create pipelines
- Governance: Define ownership, standards, monitoring
- **Deliverable:** Clean datasets, data pipelines, governance framework
- **Critical:** Don't skip! 85% of AI failures due to poor data

**Phase 3: Model Development (Months 5-7)**

- Select algorithms (supervised/unsupervised, pre-trained vs custom)
- Train: Split data 70/15/15 (train/validate/test), feature engineering, tuning
- Validate: Accuracy >85%, business impact, bias testing, explainability
- Document: Model card, benchmarks, limitations, ethical considerations
- **Deliverable:** Trained models, validation report, deployment plan

**Phase 4: Pilot (Months 8-10)**

- Define pilot scope with rollback plan
- User training on capabilities and limitations
- Shadow mode: AI runs alongside existing process, no business impact
- Feedback loop: Collect user feedback, monitor performance, refine
- **Deliverable:** Pilot results, feedback summary, go/no-go decision
- **Don't rush:** Typical pilot 3-6 months

**Phase 5: Enterprise Rollout (Months 11-18)**

- Phased rollout: Site-by-site, asset-by-asset
- Change management: Communication, training, support
- Operational handoff: Document procedures, establish monitoring
- Continuous improvement: Monthly reviews, quarterly retraining, annual strategy
- **Deliverable:** Production deployment, runbook, ROI achievement

### Four Critical Success Factors

**1. Executive Sponsorship**

```
Required:
- Budget ($250K-$1M+ enterprise)
- Organizational change authority
- Cross-functional collaboration
- 12-24 month commitment

Without: Projects stall, budget cut, teams don't collaborate
With: Clear priority, resources allocated, barriers removed
```

**2. Data Quality**

```
Rule: AI quality <= Data quality

Investment:
- 50% of project time on data
- Establish governance
- Continuous monitoring
- Quality metrics
```

**3. Human-in-the-Loop**

```
Bad: "AI makes all decisions"
- No oversight
- Errors compound
- Loss of expertise

Good: "AI suggests, human decides"
- AI provides recommendations
- Human reviews and confirms
- Feedback improves AI
- Expertise preserved

Risk Levels:
- High (safety/cost >$50K): Human approval required
- Medium (cost $5K-$50K): Human review
- Low (cost <$5K): Auto-execute with audit
```

**4. Explainability**

```
Black Box (Bad):
AI: "Asset will fail in 7 days"
User: "Why?"
AI: "Trust me"
User: "I don't"

Explainable (Good):
AI: "Asset will fail in 7 days"
User: "Why?"
AI: "Vibration 3x normal, temperature +15 C,
     12 historical failures with same pattern"
User: "Makes sense, scheduling maintenance"

Techniques: SHAP, LIME, feature importance, decision trees
```

> **Key insight:** Invest 50% of your AI project time on data foundation. 85% of AI failures stem from poor data, not algorithm selection. The five-phase model (business case, data foundation, model development, pilot, rollout) takes 12-18 months -- rushing the pilot phase causes 70% of production failures.

---

## Part 4: Governance and Ethics

### Governance Structure

```
┌─────────────────────────────────────────┐
│     AI Governance Board                 │
│  (Strategy, Ethics, Risk)               │
├─────────────────────────────────────────┤
│ Members:                                │
│ - Chief Data Officer (Chair)            │
│ - CIO, Head of Maximo/EAM              │
│ - Legal, Ethics officer                 │
│ - Business unit leaders                 │
├─────────────────────────────────────────┤
│ Responsibilities:                       │
│ - Approve AI use cases                  │
│ - Set ethical guidelines                │
│ - Monitor AI risks                      │
│ - Ensure compliance                     │
│ - Review incidents                      │
└─────────────────────────────────────────┘
            ↓
┌─────────────────────────────────────────┐
│      AI Project Teams                   │
│  (Implementation, Operations)           │
├─────────────────────────────────────────┤
│ - Data scientists, ML engineers         │
│ - Maximo admins, Business analysts      │
│ - Subject matter experts                │
└─────────────────────────────────────────┘
```

### Four Ethical Principles

**1. Transparency**

- Label AI-generated content clearly
- Explain how AI reached conclusions
- Provide confidence scores
- Document model limitations

**Example:**

```
AI-GENERATED CONTENT

[Description text...]

Generated by: watsonx.ai v1.2
Confidence: 87%
Based on: 14 similar work orders
Please review and edit as needed
```

**2. Human Oversight (Risk-Based)**

- **High Risk:** Safety-critical, major capital ($50K+), regulatory -- Human approval required
- **Medium Risk:** WO classification, predictive triggers, moderate cost ($5K-$50K) -- Human review
- **Low Risk:** Data quality, information lookup, low cost (&lt;$5K) -- Auto-execute with audit

**3. Fairness and Bias Mitigation**

- Risk: Predictive maintenance bias toward well-instrumented assets, urban vs rural
- Mitigation: Diverse training data, regular bias audits, fairness metrics, human review

**4. Accountability**

- Clear responsibility matrix for AI decisions
- Document who approved model deployment
- Track model changes and performance
- Incident response procedures
- Regular governance reviews

### Model Monitoring and Maintenance

```
Continuous Monitoring:
- Performance metrics (accuracy, precision, recall)
- Model drift detection
- Data quality degradation
- Bias metrics
- Business impact metrics

Retraining Schedule:
- Monthly: Review performance
- Quarterly: Retrain models with new data
- Annually: Comprehensive model audit
- Ad-hoc: When performance degrades >10%

Incident Response:
1. Detect issue (automated alerts)
2. Assess impact (business + technical)
3. Immediate action (disable model if critical)
4. Root cause analysis
5. Fix and redeploy
6. Post-mortem review
```

---

## Part 5: The Future Roadmap

### Near-Term (1-2 Years)

**Enhanced RAG Capabilities**

- Multi-modal RAG (text + images + sensor data)
- Real-time context from IoT streams
- Personalized responses based on user role and expertise

**Autonomous Work Order Generation**

- Predict then Generate WO then Route to planner then Auto-schedule
- Human approval for high-risk only
- Learning from planner feedback

**AI-Powered Scheduling**

- Optimize technician routes with real-time traffic
- Balance workload across team
- Account for skills, certifications, availability
- Predict job duration based on historical data

### Mid-Term (2-4 Years)

**Autonomous Mobile Inspections**

- Drones perform inspections autonomously
- Edge AI processes images in real-time
- Auto-generate inspection records
- Only alert humans for critical defects

**Prescriptive Maintenance**

- Beyond prediction: Recommend specific actions
- "Replace bearing AND adjust alignment AND increase lubrication frequency"
- Optimize maintenance strategy per asset

**AI Copilots**

- Embedded assistant in every Maximo screen
- Contextual help based on current task
- Proactive suggestions
- Natural language commands

### Long-Term (4+ Years)

**Self-Healing Assets**

- AI detects anomaly
- Attempts automated correction
- Generates WO only if auto-correction fails
- Examples: Restart stuck process, adjust parameters, clear buffers

**Collaborative Human-AI Teams**

- AI as team member, not tool
- AI participates in planning meetings
- AI learns from human decisions
- Humans learn from AI insights
- Symbiotic intelligence

**Industry-Specific AI Models**

- Utilities-specific failure prediction
- Manufacturing-specific quality control
- Transportation-specific route optimization
- Pre-trained on industry best practices

---

## Key Takeaways

1. **AI success requires specific business problems, not technology mandates** -- The $850K success story addressed quantified problems (47-min work order time, 62% false positives, 450 hours manual inspection) with measurable solutions, not "we need AI" initiatives.
2. **Data quality determines AI quality** -- Invest 50% of project time on data foundation; 85% of AI failures stem from poor data, not algorithm selection or infrastructure.
3. **Five proven use cases deliver immediate ROI** -- Work order intelligence (75% time savings), predictive maintenance (60% cost reduction), visual inspection (81% time savings), conversational assistant (40 min/WO saved), data quality (97% accuracy) all proven in production.
4. **watsonx integration provides enterprise-grade AI** -- watsonx.ai (foundation models + RAG), watsonx.data (governed data lake), watsonx.governance (model monitoring) purpose-built for asset management, not general-purpose AI.
5. **Implementation follows five phases over 12-18 months** -- Business case (1 month), data foundation (3 months), model development (3 months), pilot (3 months), enterprise rollout (6 months); rushing pilots causes 70% of production failures.
6. **Human-in-the-loop is mandatory, not optional** -- High-risk decisions (safety, >$50K) require human approval; medium-risk need human review; only low-risk (&lt;$5K) can auto-execute with audit trails.
7. **Explainability builds trust and adoption** -- "Vibration 3x normal, temperature +15 C, 12 similar failures" drives action; "Trust me" drives skepticism; SHAP/LIME techniques make black boxes transparent.
8. **Maximo Predict combines three model types** -- Failure probability (Random Forest), remaining useful life (LSTM), anomaly detection (Isolation Forest) provide complementary insights for condition-based maintenance.
9. **Visual inspection automation achieves 96% accuracy** -- Computer vision models trained on 1000+ images per defect type, deployed to edge devices (drones), process images at 5-20/second with &lt;200ms inference time.
10. **RAG architecture retrieves then generates** -- Vector database search finds top 5 relevant documents (manuals, work orders, procedures), LLM synthesizes into contextual response, enabling conversational AI without hallucinations.
11. **Executive sponsorship and governance are non-negotiable** -- AI Governance Board (CDO, CIO, Legal, Ethics) approves use cases, monitors risks, ensures compliance; without governance, 73% of AI projects fail regulatory audits.
12. **Future is autonomous but human-centered** -- Near-term (1-2 years): Autonomous work order generation with human approval; Mid-term (2-4 years): Prescriptive maintenance and AI copilots; Long-term (4+ years): Self-healing assets with symbiotic human-AI intelligence.

---

## Conclusion: Practical AI, Not Magic

The difference between AI hype and AI value comes down to discipline:

**Hype Pattern:**

- "We need AI!"
- Invest in infrastructure
- Hope for use cases
- $2M spent, zero production deployments
- Quietly canceled

**Value Pattern:**

- Identify specific business problem
- Quantify current cost/time/quality
- Assess data availability and quality
- Select appropriate AI technique
- Pilot with clear success metrics
- Scale based on proven ROI

The five use cases in this blog aren't science fiction -- they're running in production today, delivering measurable ROI. Work order intelligence saves 35 minutes per WO. Predictive maintenance reduces unplanned downtime 73%. Visual inspection processes 6x more frequently at 87% lower cost.

The technology works. The question isn't "Can AI help Maximo?" but rather "Which business problem should we solve first?"

Start with one use case. Get data quality right. Pilot thoroughly. Scale methodically. Measure relentlessly.

AI in Maximo isn't about replacing humans -- it's about amplifying their expertise, capturing tribal knowledge, and making better decisions faster.

In Part 11 of this series, we'll explore a real MAS migration case study, showing how a global manufacturer successfully navigated the transformation from 7.6.x to MAS while implementing these AI capabilities.

---

## References

- [IBM watsonx Documentation](https://www.ibm.com/docs/watsonx)
- [Maximo Predict Implementation Guide](https://www.ibm.com/products/maximo/predictive-maintenance)
- [Maximo Visual Inspection Documentation](https://www.ibm.com/docs/en/mas-cd/maximo-vi)

---

**Previous:** [Part 9 - Enterprise Architecture: MAS as Platform](/posts/THINK-MAS/enterprise-architecture-mas-platform)

**Next:** [Part 11 - A Real MAS Migration Case Study](/posts/THINK-MAS/real-mas-migration-case-study)

**Series:** THINK MAS -- Modern Maximo | Part 10 of 12
